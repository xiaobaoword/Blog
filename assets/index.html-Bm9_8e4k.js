import{_ as a,c as r,a as n,o as t}from"./app-DNIo-6hg.js";const s={};function p(l,e){return t(),r("div",null,e[0]||(e[0]=[n('<h2 id="概述" tabindex="-1"><a class="header-anchor" href="#概述"><span>概述</span></a></h2><p>Elasticsearch 是 <strong>JAVA</strong> 语言开发基于 <strong>Lucene</strong> 一个 <strong>分布式</strong> 的、基于 Lucene 的 <strong>搜索引擎</strong> 和 <strong>分析引擎</strong>。</p><p>它能够快速地存储、搜索和分析大量数据。</p><p>Elasticsearch 经常用于日志分析、实时应用监控、全文检索等场景。</p><p>它的特点包括高扩展性、近实时搜索能力以及对结构化和非结构化数据的支持。</p><h2 id="分布式" tabindex="-1"><a class="header-anchor" href="#分布式"><span>分布式</span></a></h2><h2 id="搜索引擎" tabindex="-1"><a class="header-anchor" href="#搜索引擎"><span>搜索引擎</span></a></h2><h3 id="倒排索引" tabindex="-1"><a class="header-anchor" href="#倒排索引"><span>倒排索引</span></a></h3><p>倒排索引作为ES的核心，底层基于Lucene进行实现。</p><p>倒排索引（Inverted Index）也叫反向索引，有反向索引必有正向索引。</p><p>通俗地来讲，正向索引是通过文档ID找单词。反向索引则是通过单词找文档ID。</p><h2 id="分析引擎" tabindex="-1"><a class="header-anchor" href="#分析引擎"><span>分析引擎</span></a></h2><h3 id="文本分析-analysis" tabindex="-1"><a class="header-anchor" href="#文本分析-analysis"><span>文本分析（Analysis）</span></a></h3><p>文本分析是将全文本拆分为一系列最小单元（token）的过程，称为分词。</p><p>它是自然语言处理（NLP）领域中的重要过程。</p><p>这个过程是通过分词器（Analyzer）来实现的，es有内置的分词器、也有自定义分词器。</p><h3 id="分词器-analyzer" tabindex="-1"><a class="header-anchor" href="#分词器-analyzer"><span>分词器（Analyzer）</span></a></h3><p>分词器（Analyzer）由三个核心部分组成：</p><ul><li><p>字符过滤器（Character Filters）</p></li><li><p>分词器（Tokenizer）</p></li><li><p>token 过滤器（Token Filters）</p></li></ul><p>它们按照<strong>顺序</strong>依次处理文本，完成从原始文本到可索引词条（Terms）的转换。</p><h4 id="_1-字符过滤器-character-filters" tabindex="-1"><a class="header-anchor" href="#_1-字符过滤器-character-filters"><span>1. 字符过滤器（Character Filters）</span></a></h4><p>文本分析的第一步，对原始文本进行预处理。</p><p>它用于筛选、转换或移除特定字符，例如：移除HTML标签、转换为小写、替换某些字符等。</p><h4 id="_2-分词器-tokenizer" tabindex="-1"><a class="header-anchor" href="#_2-分词器-tokenizer"><span>2. 分词器（Tokenizer）</span></a></h4><p>文本分析的第二步，字符串被分词器按照规则分为单个的单词，它的功能是将连续的文本分割成一个个独立的单元（如单词或子词），这些单元是更小的词条，被称为 tokens。</p><p>这对于后续的各种文本处理任务（如机器翻译、情感分析等）是非常关键的步骤。不同的语言可能需要不同类型的分词器，因为语言结构和语法规则各不相同。例如，在英文中，分词器可以根据空格来区分单词；而在中文中，则需要更复杂的算法来识别词语的边界。</p><p><strong>功能</strong></p><ul><li><p>分割文本：根据空格、标点符号或其他规则将文本拆分为 tokens。</p></li><li><p>生成词汇单元：确保每个 token 是有意义的词语或符号。</p></li></ul><p><strong>Elasticsearch 的内置分词器</strong></p><ul><li><p>Standard Analyzer - 默认分词器，按词切分，小写处理</p></li><li><p>Simple Analyzer - 按照非字母切分(符号被过滤)，小写处理</p></li><li><p>Stop Analyzer-小写处理，停用词过滤(the，a，is)</p></li><li><p>Whitespace Analyzer - 按照空格切分，不转小写</p></li><li><p>Keyword Analyzer - 不分词，直接将输入当作输出</p></li><li><p>Patter Analyzer - 正则表达式，默认\\W+(非字符分隔)</p></li><li><p>Language - 提供了30多种常见语言的分词器</p></li><li><p>Customer Analyzer 自定义分词器</p></li></ul><h4 id="_3-token-过滤器-token-filters" tabindex="-1"><a class="header-anchor" href="#_3-token-过滤器-token-filters"><span>3. token 过滤器（Token Filters）</span></a></h4><p>文本分析的第三步，它们对已经分词后的 token 进行进一步的处理或转换。与字符过滤器不同，token 过滤器不会改变原始文本，而是直接操作已经生成的 token。</p><div class="hint-container warning"><p class="hint-container-title">注意</p><p>这里的token经常混淆，有被称为 term，token，词元，词项，词条诸如此类的名词，所以直接称为 <strong>token</strong></p><p>token 是一个在分词阶段中产生的最小单位，也是一个 Tokne 对象</p><p>term 是一个在构建倒排索引阶段产生的最小单位，也是一个 Term 对象。</p></div><p><strong>功能</strong></p><ul><li><p>大小写转换：将所有 tokens 统一为小写或大写形式。</p></li><li><p>去除停用词：移除常见的无意义词汇，如“the”、“is”、“a”等。</p></li><li><p>词干提取：将词语还原为其词根形式（例如，“running” -&gt; “run”）。</p></li><li><p>同义词扩展：根据同义词表将某个 token 替换为多个同义词。</p></li><li><p>词形还原：将词语还原为标准形式（例如，“better” -&gt; “good”）。</p></li><li><p>n-gram 生成：为每个 token 生成连续的 n-gram 或前缀 n-gram。</p></li></ul><h2 id="问题" tabindex="-1"><a class="header-anchor" href="#问题"><span>问题</span></a></h2><h3 id="es写入数据的工作原理是什么" tabindex="-1"><a class="header-anchor" href="#es写入数据的工作原理是什么"><span>ES写入数据的工作原理是什么？</span></a></h3><h3 id="es查询数据的工作原理是什么" tabindex="-1"><a class="header-anchor" href="#es查询数据的工作原理是什么"><span>ES查询数据的工作原理是什么？</span></a></h3><h2 id="学习资料" tabindex="-1"><a class="header-anchor" href="#学习资料"><span>学习资料</span></a></h2><p><a href="https://time.geekbang.org/course/intro/100030501" target="_blank" rel="noopener noreferrer">极客时间-Elasticsearch核心技术与实战 阮一鸣</a> <a href="https://www.youtube.com/playlist?list=PLn5XLkWHBxyuTUqxpuwdPEwO3ZoxwhkyS" target="_blank" rel="noopener noreferrer">🔨</a></p><p><a href="https://elasticstack.blog.csdn.net/?type=blog" target="_blank" rel="noopener noreferrer">Elastic 中国社区官方博客</a></p><p><a href="https://developer.aliyun.com/article/941168" target="_blank" rel="noopener noreferrer">ElasticSearch核心知识讲解</a></p><h3 id="logstash" tabindex="-1"><a class="header-anchor" href="#logstash"><span>Logstash</span></a></h3><p>入门跟练</p><p><a href="https://blog.csdn.net/UbuntuTouch/article/details/105973985" target="_blank" rel="noopener noreferrer">Logstash：Logstash 入门教程 （一）</a></p><p><a href="https://elasticstack.blog.csdn.net/article/details/105979677" target="_blank" rel="noopener noreferrer">Logstash：Logstash 入门教程 （二）</a></p><p><a href="https://blog.csdn.net/UbuntuTouch/article/details/100727051" target="_blank" rel="noopener noreferrer">Logstash：把 Apache 日志导入到 Elasticsearch</a></p><h2 id="to-do-list" tabindex="-1"><a class="header-anchor" href="#to-do-list"><span>to do list</span></a></h2><p>Elasticsearch 工程师认证考试</p>',49)]))}const o=a(s,[["render",p],["__file","index.html.vue"]]),h=JSON.parse('{"path":"/middleware/elasticsearch/","title":"Elasticsearch","lang":"zh-CN","frontmatter":{"title":"Elasticsearch","createTime":"2024/12/18 10:40:11","permalink":"/middleware/elasticsearch/"},"headers":[],"readingTime":{"minutes":3.81,"words":1142},"git":{"updatedTime":1738825692000,"contributors":[{"name":"houxiaobao","username":"houxiaobao","email":"","commits":6,"avatar":"https://avatars.githubusercontent.com/houxiaobao?v=4","url":"https://github.com/houxiaobao"}]},"filePathRelative":"notes/middleware/elasticsearch/README.md","bulletin":false}');export{o as comp,h as data};
